\documentclass[12pt]{article}

\usepackage{epsfig}
\usepackage{graphics}
\usepackage{color}

\begin{document}

\title{Solution: Sonny Bayes Robs a Train} 
\author{David Johnston \\ThoughtWorks\\dajohnst@thoughtworks.com}
\maketitle

\section{A Bayesian Approach}

I know of no way of solving this problem with using a Bayesian approach. It demonstrates most
starkly the need to introduce a reasonalble prior distribution. Let's introduce two variables that
define the uncertainty in the problem. Let $x$, a continuous value, denote the unknown amount of gold initially 
loaded into each of the trains. We'll make it an integer in dollars just so we can use sums rather than integrals. 
Therefore one of the running trains has $x$ amount of gold and the other has $2x$. 
Let us also define another parameter $L$, a Boolean defining their Luck. $L$ is True if their random guess resulted
in them arriving first at the train with more gold and False otherwise. Initially these are indepenedent variables
but they become perfectly correlated once some data come in as we shall see. Finally let $D$ denote the data which
in this case is just the fact that they have discovered about 10 million in gold on one of the trains. 

\section{The General Solution}

We will proceed, as always, by writing down the probability that we desire and apply Bayes theorem to get someting that
we can calculate numerically. We are interested in the posterior probability of $L$ given the new data. This is
\begin{equation}
P(L | D) = \sum_x P(L, x | D)
\end{equation}
This is a common pattern in Bayesian statsitics. Though we only care about the marginal distribution $P(L | D)$, we
need to demarginalize it in order to be able to do the calculation. Now we can apply Bayes theorem to $P(L,x | D)$
\begin{eqnarray}
P(L, x | D) &=& P(D | L, x) P(L,x) / P(D)\\
&\propto& P(D | L, x) P(L|x) P(x)
\end{eqnarray}
As is common, we don't care about the normalization constant $P(D)$ so we throw it away and change it from an equation to 
a proprtionality statement. If that is confusing, you can keep it. You will see that it will drop out anyway. 

We can put this into the equation above and now we have 
\begin{equation}
P(L | D) \propto \sum_x P(D | L, x) P(L|x) P(x)
\end{equation}

This is now in a form that we can work with. That is, we can logically assign numbers to each of these three terms 
in the sum. Let's start with $P(D | L,x)$. This is called the likelihood of the data. More specifically, we can call
it the \emph{complete} likelihood because we are including both variables. What is the value of this term? It's usualy
helpful to spell these things out in words. This is: What is the probability of observing D=10 (or any amount) 
given that we know $L$ and also know $x$. For example, if $x=5$ million and $L=True$, the probability is 1 
because we were lucky to choose the best train and 2 times $x=5$ is 10. For any other value of $x$ it will be zero. 
If instead we know $L=False$, this will be zero for every value except when $x=10$. 

What about $P(L | x)$. We chose the first train at random and so it cannot depend on $x$. This implies that 
$P(L | x) =0.5$ for both values of $L$. It's just another constant factor that will drop out. 

Finally, there is $P(x)$. This is the prior distrubution on $x$. It embodies our expectation of the value of $x$ before 
receiving the new data that there is 10 million worth of gold on one of the trains. Often, it is the case that the 
prior is not that important and in fact it gets less important as you add new data. In this case, the only other piece 
of data would be the amount of gold on the other train. If we knew that we wouldn't care about the prior or even bother 
thinking about this in a Bayesian fashion. But in this problem, with only one data point, it turns out that the prior is not 
just important; it determines the problem entirely. 

Let's get back to our equation and calculate $P(L | D)$ for each of the possible values of $L$ which are True and False
not that we know that $P(L|x)$ is a negligle constant and $P(L,x | D)$ acts to collapse the sum down to one single
term (depending on $L$). 

We can put this into the equation above and now we have
\begin{equation}
P(L= True | D) \propto P(x = 5)
\end{equation} 
and 
\begin{equation}
P(L= False | D) \propto P(x = 10)
\end{equation}
 
Now we know (assuming we trust our informant) that $P(L= True | D) + P(L= False | D) =1$ because, 
regardless of the data, we know that $L$ is either True or False. This is a common trick. We wait until the
end to normalize our posteriors rather than carrying around a lot of proportionality factors that will just be
absorbed into this constant anyway. The properly normalized $P(L | D)$, for either $L$, is clearly. 

\begin{equation}
P(L | D) = \frac{P(L | D)}{P(L=True | D) + P(L=False | D)}
\end{equation}

So for example, 
\begin{equation}
P(L=True | D) = \frac{1}{1+\frac{P(L=False | D)}{P(L=True|D)}}
\end{equation}
The last step in the formal solution is to plug in the value of this ratio. Again notice how any
common constant factors drop out. 
\begin{equation}
P(L=True | D) = \frac{1}{1+\frac{P(x=10)}{P(x=5)}}
\label{eq:final}
\end{equation}
As mentioned before, the answer of whether $P(L=True | D)$ (we should take the gold) is greater than
$P(L=False | D)$ (we should rob the other train) depends entirely on our prior distribution evalued at 
our data point and half that value. 

\section{Uniform Prior}

For example, if we use a uniform prior, i.e. one that is the same for all $x$, $P(L=False | D)=0.5$ and so 
there is no incentive to drop the gold and rob the other train though if they did, they should expect the 
same amout of gold. More precisely, the expectaton value of gold is the same whether or not they switch. But if
they take the gold, they know exactly how much they get. There is zero variance. If they swicth, the expectation
value is the same but the variance is non zero. If like most people you decide to not accept risk (uncertaintly) 
with no expected reward, you'll take the gold and go. If you are the gambling sort who likes risk even with no expected
reward you might wanto to try your luck with the other train. Given that guns are out, you are probably better ending
the job here. 

This is the general solution for any prior but in this problem we do have real prior information. There is no reason
to assume a uniform prior. The train robbers have each seen three trains and counted the gold on each. Thus, they can 
construct a useful prior and make a more educated guess. 

So if the train robbers observations of these 9 trains has yielded the following list of approximate amounts
\{14 14  7 13 10 15  7  8 12\} you can build some kind of distribution that you can evaluate at $x=5$ and $x=10$. 
Note that the mean of these is 11.1 with a standard deviation of about 3. From that alone we can decide what to
do. Both $x=5$ and $x=10$ are lower than the mean and $x=5$ would be the lowest of 10 sampled points. It seems
that $x=10$ has a higher prior probability and so we should indeed drop the gold and rob the other train
assuming the risk of failure in robbing that other train is assumed minimal. 

If we assume some risk of failure in robbing the second train, we might want to try to calculate this more
accurately. One way of doing this is to assume some distribution. 

\section{Normal distribution prior}

Let's try the normal distribution. The sample mean 11.1 is also the maximum likelihood estimator for the
normal distribution mean and the $N/(N-1) s^2$ is the ML estimator for the distribution variance with N=9 which 
is still about 3.  The prior is 
\begin{equation}
P(x) = \frac{1}{\sigma \sqrt{2 \pi}} \exp\left[ -1/2 ((x-\mu)/\sigma)^2   \right]
\end{equation}

Now look at Equation \ref{eq:final}. When $L=True$ we know $x=5 = D/2$. When $L=False$ we know $x=10 = D$. Let's leave 
this in terms of $D$ to get a formula for the general solution. Pluggin this in, we can 
write Equation \ref{eq:final} after a little albegra as 
\begin{equation}
P(L=True | D) = \frac{1}{1+\exp \left[  -D (3 D/4-\mu)/(2\sigma^2)  \right]}
\label{eq:final}
\end{equation}

From this we can see right away what we should do, assuming no risk of failing to rob the second train. The
decision depends on the sign of $3/4 D - \mu$ because this determines whether the exponential is greater than
1 which determines whether $P(L=True | D) > 0.5$. For $mu=11.1$, the crossing point is $D=14.8$. If D were greater
than this, we should keep the gold and not rob the second train. 

\section{The Professional Solution}

If these train robbers we're true professionals and considered real risks of being successful, they would perform 
the following calculation for the cut-off value for the gold on the first train. If the amount was clearly less than the
cut-off value, they could leave immediately and rob the other train. If the opposite were true, they would just pack it up.
If it was unclear, they could count it and then decide. There is also the concept of utility to consider.

\subsection{utility function}

We have been assuming that the measure they want to maximize is the expectation value of the amount they will
steal. In reality, people's preferences are usually more complex than that. People also care about volatility/risk 
and they often have a preference for money or any other measureable thing that is non-linear. This is known
as utility. In the example above the utility as a function of $x$ is simply $U(x) = x$. It could be some 
other function. 

If you won a billion dollars, would you then accept a 50-50 coin toss where 
you either lose your billion dollars or win 5 more billion?  
If all you cared about was maximizing your expectation value, you should. But any sane person who is not already
a billionaire would reject this because they would likely conclude that their life wouldn't be terribly different 
with 5 billion instead of 1 but that there would be a huge difference from their current middle class lifestyle and
that of a billionaire. You'd almost certainly decline that offer.  

In regards to this problem, the train robbers would probably come to the same conclusion that 5 versus 10 is a 
bigger difference than 10 versus 20. The curve, which may vary from person to person, 
is usually concave, resembling the curve $U(x) = \sqrt{x}$ or something like it.   

\subsection{factoring in risk}

To make this train robbery example more realistic, we would have to factor in that there is some risk that
if they leave the first train, they will get caught trying to sneak onto the second one. Presumably they
considered this risk before even robbing the first one.  

Let's say they conclude that they agree that there is a 10\% chance of getting caught
and that they concluded that it would be worth that risk if they each
got 1 million each so they need to find 3 million on the train to 
make it worth it. Based on their past experienced, they expect to find
at least that much and so they move ahead with the robery. This cut
off point of 3 million allows us to assign a negative utility to the
getting caught scenario of -3 million. 


\section{Conclusion: What we have learned}


\end{document}
